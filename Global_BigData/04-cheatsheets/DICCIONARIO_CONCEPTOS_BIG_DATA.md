# üìö DICCIONARIO DE CONCEPTOS BIG DATA
## Gu√≠a Completa de T√©rminos para el M√≥dulo Completo

---

## üéØ **C√ìMO USAR ESTE DICCIONARIO**

**Para Estudiantes:**
- üìñ Consulta ANTES de cada sesi√≥n para prepararte
- üîç Busca t√©rminos durante exercises pr√°cticos
- ‚úÖ Valida tu entendimiento despu√©s de cada sesi√≥n

**Para Instructores:**
- üéì Reference r√°pida durante explicaciones
- üìã Checklist de conceptos que estudiantes deben dominar
- üîß Troubleshooting cuando estudiantes se confunden

**Nivel de Dificultad:**
- üü¢ **B√°sico**: Fundamental para entender
- üü° **Intermedio**: Importante para practice
- üî¥ **Avanzado**: Para optimization y troubleshooting

---

## üé™ **SESI√ìN 0: FOUNDATION - CONCEPTOS BASE**

### **üü¢ SISTEMAS DISTRIBUIDOS**
**Definici√≥n**: M√∫ltiples computadoras trabajando juntas como si fueran una sola
**Analog√≠a**: Como una orquesta - muchos m√∫sicos, un director, una sinfon√≠a
**Ejemplo Real**: Google Search usa miles de servidores para responderte en 0.3 segundos
**Por qu√© Importa**: Base de todo Big Data moderno
**Relacionado con**: Cluster, Load Balancing, Fault Tolerance

### **üü¢ DOCKER**
**Definici√≥n**: Tecnolog√≠a que empaca aplicaciones con todo lo que necesitan
**Analog√≠a**: Como contenedores de barco - todo empacado, funciona en cualquier puerto
**Ejemplo Real**: Netflix despliega miles de containers por d√≠a
**Por qu√© Importa**: Hace que setup sea autom√°tico y reproducible
**Comandos Clave**: `docker ps`, `docker-compose up -d`

### **üü¢ CLUSTER**
**Definici√≥n**: Grupo de computadoras coordinadas que trabajan juntas
**Componentes**: Master (coordinador) + Workers (ejecutores)
**Ejemplo Real**: Cluster de Spark con 1 Master + m√∫ltiples Workers
**Por qu√© Importa**: Permite escalabilidad horizontal
**Relacionado con**: HDFS Cluster, Spark Cluster, Kafka Cluster

### **üü° ESCALABILIDAD HORIZONTAL vs VERTICAL**
**Vertical (Scale Up)**: Hacer UNA computadora m√°s poderosa
- Pros: Simple, no coordinaci√≥n
- Cons: L√≠mites f√≠sicos, muy caro
**Horizontal (Scale Out)**: Agregar M√ÅS computadoras
- Pros: Sin l√≠mites, m√°s barato
- Cons: Complejidad de coordinaci√≥n
**Big Data Choice**: Siempre horizontal

### **üü° CAP THEOREM**
**Definici√≥n**: En sistemas distribuidos solo puedes tener 2 de 3:
- **C**onsistency: Todos ven los mismos datos
- **A**vailability: Sistema siempre disponible  
- **P**artition Tolerance: Funciona aunque fallen conexiones
**Ejemplos Reales**:
- Google Search: A + P (disponible, datos pueden variar)
- Bancos: C + P (datos exactos, puede no estar disponible)
**Por qu√© Importa**: Entender trade-offs de dise√±o

### **üü° DATA LOCALITY**
**Definici√≥n**: Mover c√≥digo hacia datos, no datos hacia c√≥digo
**Regla de Oro**: C√≥digo (KB) viaja f√°cil, Datos (GB) viajan caro
**Ejemplo**: En lugar de traer 10GB a 1 servidor, enviar 10KB de c√≥digo a 10 servidores
**Impacto**: Reduce network I/O en 1000x
**Aplicaci√≥n**: Fundamento de MapReduce, Spark, HDFS

### **üü° IDEMPOTENCY**
**Definici√≥n**: Ejecutar operaci√≥n m√∫ltiples veces = mismo resultado que una vez
**Ejemplo Bueno**: `SET balance = 1000` (seguro repetir)
**Ejemplo Malo**: `ADD 100 to balance` (peligroso repetir)
**Por qu√© Importa**: Permite retry seguro cuando fallan operaciones
**Aplicaci√≥n**: Kafka consumers, Spark tasks, API calls

### **üü¢ FAULT TOLERANCE**
**Definici√≥n**: Sistema sigue funcionando aunque componentes fallen
**Filosof√≠a**: Dise√±ar ASUMIENDO que cosas van a fallar
**Estrategias**: Replicaci√≥n, Redundancia, Auto-recovery
**Ejemplo Real**: Netflix pierde 100 servidores/d√≠a, usuarios no se dan cuenta
**Relacionado con**: Replication, High Availability, Disaster Recovery

---

## üóÇÔ∏è **SESI√ìN 1: HDFS - STORAGE DISTRIBUIDO**

### **üü¢ HDFS (Hadoop Distributed File System)**
**Definici√≥n**: Sistema de archivos que distribuye datos entre m√∫ltiples servidores
**Inspiraci√≥n**: Google File System (GFS)
**Caracter√≠stica Clave**: Write-once, read-many
**Use Cases**: Data Lakes, ETL storage, Analytics datasets
**No es bueno para**: Random access, low latency, small files

### **üü¢ NAMENODE**
**Definici√≥n**: Master node que guarda metadatos del filesystem
**Funci√≥n**: "Bibliotecario" que sabe d√≥nde est√° cada archivo
**Almacena**: Ubicaciones de blocks, permisos, timestamps
**NO almacena**: Los datos reales (esos est√°n en DataNodes)
**Punto Cr√≠tico**: Si falla = cluster no funciona (necesita HA)

### **üü¢ DATANODE**
**Definici√≥n**: Worker nodes que almacenan los datos reales
**Funci√≥n**: "Estantes" que guardan los blocks de archivos
**Responsabilidades**: Reportar estado, servir reads/writes, replicar data
**Heartbeat**: Reporta a NameNode cada 3 segundos
**Auto-recovery**: Si falla, NameNode usa r√©plicas autom√°ticamente

### **üü° BLOCKS**
**Definici√≥n**: Pedazos de 128MB en que HDFS divide archivos grandes
**Por qu√© 128MB**: Balance entre overhead y distribuci√≥n
**Distribuci√≥n**: Cada block se replica en m√∫ltiples DataNodes
**Ejemplo**: Archivo 1GB = 8 blocks de 128MB cada uno
**Benefit**: Paralelismo (multiple DataNodes leen simult√°neamente)

### **üü° REPLICATION**
**Definici√≥n**: Cada block se copia autom√°ticamente en m√∫ltiples DataNodes
**Default**: Factor 3 (cada block en 3 lugares diferentes)
**Rack Awareness**: Primera copia local, segunda en diferente rack
**Trade-off**: M√°s r√©plicas = m√°s seguridad + m√°s espacio usado
**Auto-management**: Si nodo falla, HDFS crea nuevas r√©plicas autom√°ticamente

### **üü° METADATA**
**Definici√≥n**: Informaci√≥n SOBRE los datos (no los datos mismos)
**Incluye**: Ubicaci√≥n de blocks, tama√±os, permisos, checksums
**Storage**: Todo en memoria del NameNode para velocidad
**Backup**: FSImage (snapshot) + EditLog (cambios incrementales)
**Insight Cr√≠tico**: Metadata m√°s importante que datos (sin metadata = datos inaccesibles)

### **üî¥ FSIMAGE & EDITLOG**
**FSImage**: Snapshot completo de metadatos en disco
**EditLog**: Log de cambios desde √∫ltimo FSImage
**Checkpoint**: Secondary NameNode combina FSImage + EditLog peri√≥dicamente
**Recovery**: En caso de fallo, reconstruye metadata desde FSImage + EditLog
**HA Setup**: Usa Journal Nodes para compartir EditLog entre NameNodes

### **üü° RACK AWARENESS**
**Definici√≥n**: HDFS conoce topolog√≠a f√≠sica del datacenter
**Estrategia de Replicaci√≥n**: 
- Copia 1: Mismo rack (r√°pido)
- Copia 2: Diferente rack (seguro)
- Copia 3: Mismo rack que copia 2 (balance)
**Benefit**: Optimiza velocidad + tolerancia a fallos de rack completo

---

## ‚ö° **SESI√ìN 2: PROCESSING DISTRIBUIDO**

### **üü¢ MAPREDUCE**
**Definici√≥n**: Paradigma de programaci√≥n para procesar datos masivos en paralelo
**Fases**: Map ‚Üí Shuffle ‚Üí Reduce
**Inspiraci√≥n**: Functional programming (map/reduce functions)
**Fortaleza**: Muy robusto, fault tolerant, simple conceptualmente
**Debilidad**: Lento para workflows complejos (escribe a disco entre steps)

### **üü¢ MAP FUNCTION**
**Definici√≥n**: Transforma/filtra datos en paralelo
**Input**: Key-value pairs
**Output**: Nuevos key-value pairs
**Ejemplo**: Extraer (route_id, passenger_count) de cada l√≠nea de log
**Paralelismo**: Un mapper por input split (t√≠picamente 1 por block)

### **üü¢ REDUCE FUNCTION**
**Definici√≥n**: Agrega/combina datos con misma key
**Input**: Key + lista de todos los values para esa key
**Output**: Key + valor agregado
**Ejemplo**: Sumar passenger_count por route_id
**Constraint**: Solo ve datos de UNA key a la vez

### **üü° SHUFFLE**
**Definici√≥n**: Fase donde datos se reorganizan por key entre Map y Reduce
**Proceso**: Agrupa todos values con misma key, los env√≠a al mismo reducer
**Network Intensive**: √önica fase que transfiere datos por red
**Optimization**: Combiners pueden reducir datos antes de shuffle

### **üü° COMBINER**
**Definici√≥n**: "Mini-reducer" que pre-agrega datos localmente antes de shuffle
**Benefit**: Reduce tr√°fico de red dram√°ticamente (80-95% t√≠pico)
**Requirement**: Funci√≥n debe ser asociativa y conmutativa
**Ejemplo V√°lido**: Sum, Count, Max, Min
**Ejemplo Inv√°lido**: Average (necesita numerador + denominador separados)

### **üü° PARTITIONER**
**Definici√≥n**: Decide qu√© reducer recibe cada key
**Default**: Hash partitioner (hash(key) % num_reducers)
**Custom**: Puedes crear l√≥gica custom para balancear carga
**Problema**: Default puede causar data skew si keys no distribuidas uniformemente

### **üü¢ SPARK**
**Definici√≥n**: Motor de procesamiento distribuido optimizado para velocidad
**Key Innovation**: In-memory computing entre operaciones
**Performance**: 10-100x m√°s r√°pido que MapReduce para workflows iterativos
**APIs**: Python (PySpark), SQL, Scala, Java
**Use Cases**: Analytics interactivo, Machine Learning, Streaming

### **üü¢ RDD (Resilient Distributed Dataset)**
**Definici√≥n**: Estructura de datos distribuida e inmutable de Spark
**Resilient**: Se reconstruye autom√°ticamente si partici√≥n falla
**Distributed**: Particionado autom√°ticamente entre workers
**Immutable**: No se modifica, solo se crean nuevos RDDs
**Lazy**: Transformaciones no ejecutan hasta action

### **üü° TRANSFORMATIONS vs ACTIONS**
**Transformations**: Operaciones lazy que definen nuevo RDD
- Ejemplos: map(), filter(), groupBy(), join()
- No ejecutan inmediatamente
**Actions**: Operaciones que disparan ejecuci√≥n y retornan resultados
- Ejemplos: collect(), count(), save(), show()
- Fuerzan evaluation de todo el pipeline

### **üü° LAZY EVALUATION**
**Definici√≥n**: Spark espera hasta action para ejecutar transformations
**Benefit**: Puede optimizar todo el pipeline antes de ejecutar
**Ejemplo**: Combina m√∫ltiples filters en una sola pasada
**Catalyst**: Optimizer que aprovecha lazy evaluation para generar c√≥digo optimal

### **üî¥ DAG (Directed Acyclic Graph)**
**Definici√≥n**: Spark crea grafo de dependencias entre RDDs
**Optimization**: Analiza DAG completo para optimizar ejecuci√≥n
**Stage Boundaries**: Shuffle operations crean nuevos stages
**Fault Recovery**: Si partition falla, recalcula desde dependencias en DAG

---

## üöÄ **SESI√ìN 3: SPARK AVANZADO + SQL**

### **üü¢ DATAFRAME**
**Definici√≥n**: RDD con schema (estructura de columnas tipadas)
**Benefit**: Optimizaci√≥n autom√°tica + API m√°s simple que RDD
**Performance**: 2-5x m√°s r√°pido que RDDs por optimizaciones de Catalyst
**API**: Similar a tablas SQL o pandas DataFrames
**Schema**: Estructura se infiere autom√°ticamente o se define expl√≠citamente

### **üü° CATALYST OPTIMIZER**
**Definici√≥n**: Motor de optimizaci√≥n que mejora queries autom√°ticamente
**Fases**: Parse ‚Üí Analyze ‚Üí Optimize ‚Üí Code Generation
**Optimizations**: Predicate pushdown, join reordering, constant folding
**Result**: C√≥digo Java generado optimally
**Benefit**: Escribes SQL simple, obtienes performance de expert

### **üü° PREDICATE PUSHDOWN**
**Definici√≥n**: Mover filtros lo m√°s cerca posible de los datos
**Ejemplo**: En lugar de cargar tabla completa y luego filtrar, filtrar durante carga
**Storage Benefit**: Para formatos columnares (Parquet), lee solo partitions necesarias
**Network Benefit**: Transfiere menos datos por red

### **üü° JOIN STRATEGIES**
**Broadcast Join**: Para tablas peque√±as (<10MB), copia tabla a todos los nodos
**Sort-Merge Join**: Para tablas grandes, particiona por join key y ordena
**Hash Join**: Construye hash table de tabla m√°s peque√±a
**Auto-selection**: Catalyst elige estrategia optimal autom√°ticamente

### **üü° PARTITIONING**
**Definici√≥n**: Control de c√≥mo datos se distribuyen entre workers
**Hash Partitioning**: Distribuci√≥n uniforme por hash de key
**Range Partitioning**: Por rangos de valores (√∫til para data ordenada)
**Custom Partitioning**: L√≥gica espec√≠fica del negocio
**Benefit**: Queries por partition key no necesitan shuffle

### **üü° CACHING/PERSISTENCE**
**Definici√≥n**: Mantener RDD/DataFrame en memoria para reuso
**Levels**: MEMORY_ONLY, MEMORY_AND_DISK, DISK_ONLY, etc.
**When to Cache**: Cuando mismo dataset se usa m√∫ltiples veces
**Memory Management**: Spark autom√°ticamente desaloja cache cuando necesita memoria
**Performance**: 10-100x speedup para accesos posteriores

### **üü° WINDOW FUNCTIONS**
**Definici√≥n**: Operaciones que analizan filas relacionadas sin GROUP BY
**Tipos**: RANK(), LAG(), LEAD(), SUM() OVER(), etc.
**Partitioning**: Define scope de window (PARTITION BY)
**Ordering**: Define orden dentro de window (ORDER BY)
**Use Cases**: Rankings, moving averages, comparaciones temporales

### **üî¥ DATA SKEW**
**Definici√≥n**: Distribuci√≥n desigual de datos que causa cuellos de botella
**Problema**: Una partition con millones de records, otras con miles
**Detection**: Analizar partition sizes, buscar outliers
**Solutions**: Salting, custom partitioning, separate processing para hot keys
**Impact**: Puede convertir job de 5 minutos en 45 minutos

### **üî¥ SALTING**
**Definici√≥n**: T√©cnica para distribuir hot keys agregando randomness
**Proceso**: Agregar suffix random a keys problem√°ticas
**Ejemplo**: "route_001" ‚Üí "route_001_0", "route_001_1", etc.
**Trade-off**: M√°s complejidad pero mejor distribuci√≥n
**When to Use**: Cuando tienes keys con 10x+ m√°s datos que otras

### **üî¥ ADAPTIVE QUERY EXECUTION (AQE)**
**Definici√≥n**: Optimizaci√≥n din√°mica durante ejecuci√≥n del query
**Features**: Dynamic coalescing, skew handling, join strategy switching
**Process**: Ejecuta stage ‚Üí analiza estad√≠sticas ‚Üí re-optimiza pr√≥ximo stage
**Configuration**: spark.sql.adaptive.enabled=true
**Benefit**: 2-5x speedup autom√°tico en muchos casos

### **üü° BROADCAST VARIABLES**
**Definici√≥n**: Variables read-only compartidas eficientemente a todos los workers
**Use Case**: Lookup tables, configuration data, small reference datasets
**Efficiency**: Se env√≠a una vez por worker, no una vez por task
**Example**: Broadcast peque√±a tabla para joins

### **üü° ACCUMULATORS**
**Definici√≥n**: Variables shared que solo se pueden "agregar" (counters)
**Use Cases**: Contadores, m√©tricas, debugging info
**Thread Safety**: Spark garantiza updates at√≥micos
**Visibility**: Solo driver puede leer valor final

---

## üåä **CONCEPTOS PARA SESIONES FUTURAS (4-6)**

### **üü¢ APACHE KAFKA**
**Definici√≥n**: Plataforma de streaming distribuida para eventos en tiempo real
**Architecture**: Producers ‚Üí Brokers ‚Üí Consumers
**Use Cases**: Event streaming, log aggregation, real-time analytics
**Key Features**: High throughput, fault tolerant, horizontally scalable

### **üü¢ TOPICS & PARTITIONS**
**Topic**: Canal o categor√≠a de mensajes (ej: "user_clicks", "transactions")
**Partition**: Subdivisi√≥n de topic para paralelismo y ordenamiento
**Ordering**: Garantizado dentro de partition, no entre partitions
**Scaling**: M√°s partitions = m√°s paralelismo

### **üü° PRODUCERS & CONSUMERS**
**Producer**: Aplicaci√≥n que env√≠a mensajes a Kafka topics
**Consumer**: Aplicaci√≥n que lee mensajes de Kafka topics
**Consumer Groups**: M√∫ltiples consumers trabajando juntos para paralelismo
**Offset**: Posici√≥n de √∫ltimo mensaje le√≠do por consumer

### **üü° SPARK STREAMING**
**Definici√≥n**: Extensi√≥n de Spark para procesamiento de streams en tiempo real
**Micro-batching**: Procesa streams como series de peque√±os batches
**Sources**: Kafka, TCP sockets, file systems
**Fault Tolerance**: Exactly-once processing con checkpointing

### **üü° WINDOWING**
**Definici√≥n**: Agrupar eventos de stream en ventanas de tiempo
**Tumbling Window**: Ventanas fijas sin overlap (0-5min, 5-10min)
**Sliding Window**: Ventanas con overlap (0-5min, 2-7min, 4-9min)
**Session Window**: Agrupaci√≥n por periodos de actividad

---

## üîß **CONCEPTOS OPERACIONALES**

### **üü¢ CLUSTER MANAGER**
**Definici√≥n**: Sistema que coordina recursos entre aplicaciones
**Tipos**: Spark Standalone, YARN, Kubernetes, Mesos
**Responsabilidad**: Asignar CPU/memoria, programar jobs, manejar fallos

### **üü¢ EXECUTOR**
**Definici√≥n**: Proceso worker que ejecuta tasks en un nodo
**Resources**: CPU cores y memoria asignados por cluster manager
**Lifetime**: Dura toda la aplicaci√≥n Spark
**Tasks**: M√∫ltiples tasks pueden ejecutar en paralelo en un executor

### **üü° DRIVER PROGRAM**
**Definici√≥n**: Proceso que ejecuta funci√≥n main() y coordina workers
**Responsibilities**: Crear RDDs, enviar tasks a executors, recolectar resultados
**Location**: Puede correr en cluster o en m√°quina cliente
**Failure**: Si driver falla, toda la aplicaci√≥n falla

### **üü° CHECKPOINTING**
**Definici√≥n**: Guardar estado de RDD a storage confiable
**Purpose**: Evitar recomputation costosa de RDDs complejos
**Types**: RDD checkpointing, Streaming checkpointing
**Trade-off**: Overhead de write vs protection contra failure

### **üî¥ GARBAGE COLLECTION (GC)**
**Definici√≥n**: Proceso de limpieza autom√°tica de memoria no usada
**Impact**: GC pauses pueden afectar performance
**Monitoring**: GC time deber√≠a ser <10% de task time
**Tuning**: Adjustar executor memory, usar off-heap storage

---

## üìä **M√âTRICAS Y MONITORING**

### **üü° THROUGHPUT**
**Definici√≥n**: Cantidad de datos procesados por unidad de tiempo
**Medidas**: Records/second, MB/second, GB/hour
**Factors**: Paralelismo, I/O efficiency, network bandwidth

### **üü° LATENCY**
**Definici√≥n**: Tiempo desde que llega dato hasta que se produce resultado
**Types**: End-to-end latency, processing latency
**Trade-off**: Throughput vs latency (batch size tuning)

### **üü° RESOURCE UTILIZATION**
**CPU**: Porcentaje de cores siendo usados
**Memory**: RAM usado vs disponible, cache hit rates
**Network**: Bandwidth usado para shuffle operations
**Storage**: I/O rates, disk utilization

### **üî¥ BACKPRESSURE**
**Definici√≥n**: Mecanismo para manejar cuando producer va m√°s r√°pido que consumer
**Streaming**: Adjustar batch sizes autom√°ticamente
**Kafka**: Consumer lag monitoring
**Spark**: Dynamic allocation de resources

---

## üéØ **PATRONES COMUNES Y BEST PRACTICES**

### **üü° ETL PATTERN**
**Extract**: Leer datos de m√∫ltiples fuentes (databases, APIs, files)
**Transform**: Limpiar, agregrar, enriquecer datos
**Load**: Escribir a data lake, data warehouse, o database
**Spark Role**: Procesar transformations distributively

### **üü° LAMBDA ARCHITECTURE**
**Batch Layer**: Procesamiento batch para accuracy (HDFS + Spark)
**Speed Layer**: Procesamiento real-time para latency (Kafka + Spark Streaming)  
**Serving Layer**: Combine batch + real-time results
**Trade-off**: Complexity vs comprehensive coverage

### **üü° KAPPA ARCHITECTURE**
**Single Pipeline**: Todo a trav√©s de streaming (Kafka + Spark Streaming)
**Simplicity**: Elimina complejidad de mantener dos systems
**Trade-off**: Menos optimization para pure batch workloads

### **üî¥ SMALL FILES PROBLEM**
**Problem**: HDFS ineficiente con millones de archivos peque√±os
**NameNode Impact**: Cada file consume ~150 bytes de memoria
**Performance**: M√°s overhead que datos √∫tiles
**Solutions**: Compaction, sequence files, appropriate partitioning

---

## üö® **TROUBLESHOOTING COM√öN**

### **üü° OUT OF MEMORY**
**Causes**: RDDs muy grandes, cache excesivo, data skew
**Solutions**: Increase executor memory, reduce data size, partition better
**Prevention**: Monitor memory usage, use appropriate storage levels

### **üü° SLOW PERFORMANCE**
**Causes**: Data skew, small files, poor partitioning, network bottlenecks
**Diagnosis**: Spark UI, job timeline, task distribution
**Solutions**: Repartition, cache strategically, optimize joins

### **üü° CONNECTION FAILURES**
**Causes**: Network issues, timeouts, firewall blocks
**Symptoms**: Tasks failing with connection errors
**Solutions**: Increase timeouts, check network config, retry policies

### **üî¥ DATA CORRUPTION**
**Causes**: Hardware failures, software bugs, network errors
**Detection**: Checksums, data validation, monitoring
**Recovery**: Replication, backups, recomputation from source

---

## üìñ **RECURSOS PARA PROFUNDIZAR**

### **Documentaci√≥n Oficial**
- Apache Spark: https://spark.apache.org/docs/
- Apache Hadoop: https://hadoop.apache.org/docs/
- Apache Kafka: https://kafka.apache.org/documentation/

### **Libros Recomendados**
- "Learning Spark" by Holden Karau
- "Hadoop: The Definitive Guide" by Tom White
- "Designing Data-Intensive Applications" by Martin Kleppmann

### **Cursos Online**
- Databricks Academy (gratuito)
- Coursera Big Data Specialization
- edX Introduction to Apache Spark

---

## üéØ **CHECKLIST DE COMPETENCIAS**

### **Sesi√≥n 0: Foundation** ‚úÖ
- [ ] Entiendo distributed systems thinking
- [ ] Puedo configurar Docker environment
- [ ] Comprendo fault tolerance principles
- [ ] Domino data locality concept

### **Sesi√≥n 1: HDFS** ‚úÖ  
- [ ] Explico arquitectura NameNode/DataNode
- [ ] Entiendo replication y metadata
- [ ] Puedo troubleshoot cluster issues
- [ ] Analizo distribuci√≥n de datos

### **Sesi√≥n 2: Processing** ‚úÖ
- [ ] Implemento MapReduce jobs
- [ ] Comparo MapReduce vs Spark
- [ ] Optimizo con combiners
- [ ] Entiendo lazy evaluation

### **Sesi√≥n 3: Advanced Spark** ‚úÖ
- [ ] Uso DataFrames y Catalyst
- [ ] Optimizo joins y partitioning  
- [ ] Resuelvo data skew
- [ ] Implemento complex analytics

**üéâ ¬°Usa este diccionario como tu gu√≠a definitiva para dominar Big Data!**