# ‚ö° Sesi√≥n 2: MapReduce - Divide y Vencer√°s

## üìö Objetivos de la Sesi√≥n
- Implementar jobs MapReduce de producci√≥n
- Optimizar el rendimiento de procesamiento
- Comparar MapReduce vs Spark
- Realizar troubleshooting distribuido

## üéØ Contenido

### 1. Fundamentos de MapReduce
- Paradigma de programaci√≥n
- Fases Map y Reduce
- Shuffle y Sort
- Combiner y Partitioner

### 2. Desarrollo de Jobs
- Estructura de un job
- Mappers y Reducers
- Configuraci√≥n de jobs
- Testing y debugging

### 3. Optimizaci√≥n
- Tuning de memoria
- Configuraci√≥n de slots
- Compresi√≥n de datos
- Combiners y Partitioners

### 4. Spark vs MapReduce
- Comparativa de rendimiento
- Casos de uso
- Migraci√≥n de jobs
- Decisiones arquitect√≥nicas

## üõ†Ô∏è Hands-on

### Ejercicio 1: Job B√°sico
```python
# WordCount en MapReduce
from mrjob.job import MRJob

class MRWordCount(MRJob):
    def mapper(self, _, line):
        for word in line.split():
            yield (word, 1)

    def reducer(self, word, counts):
        yield (word, sum(counts))

if __name__ == '__main__':
    MRWordCount.run()
```

### Ejercicio 2: Optimizaci√≥n
```bash
# Ejecutar job optimizado
hadoop jar hadoop-streaming.jar \
  -D mapreduce.job.reduces=10 \
  -D mapreduce.map.memory.mb=2048 \
  -files mapper.py,reducer.py \
  -mapper mapper.py \
  -reducer reducer.py \
  -input /input \
  -output /output
```

### Ejercicio 3: Comparativa
```python
# Mismo job en Spark
from pyspark import SparkContext

sc = SparkContext()
text_file = sc.textFile("hdfs:///input")
counts = text_file.flatMap(lambda line: line.split()) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("hdfs:///output")
```

## üìä Entregables
- Pipeline de an√°lisis de transporte
- Reporte de optimizaci√≥n
- Comparativa tecnol√≥gica

## üîç Recursos Adicionales
- [MapReduce Tutorial](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
- [Spark Programming Guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)
- [Performance Tuning](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)

## üéØ Pr√≥xima Sesi√≥n
- Kafka: Procesamiento en Tiempo Real
- Stream Processing
- Event Sourcing
- Arquitecturas Lambda 