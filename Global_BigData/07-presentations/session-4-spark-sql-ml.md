# ğŸ“Š SesiÃ³n 4: Spark SQL y MLlib

## ğŸ“š Objetivos de la SesiÃ³n
- Dominar Spark SQL para anÃ¡lisis de datos
- Implementar consultas SQL en Spark
- Aplicar algoritmos de MLlib
- Optimizar consultas y modelos

## ğŸ¯ Contenido

### 1. Spark SQL
- IntroducciÃ³n a Spark SQL
- CreaciÃ³n de vistas temporales
- Consultas SQL
- OptimizaciÃ³n de queries

### 2. API Estructurada
- Lectura de datos
- Escritura de datos
- ManipulaciÃ³n de DataFrames
- Joins y agregaciones

### 3. Spark MLlib
- IntroducciÃ³n a MLlib
- Pipeline de ML
- Algoritmos supervisados
- Algoritmos no supervisados

### 4. OptimizaciÃ³n
- Tuning de queries
- Caching y persistencia
- Particionamiento
- Best practices

## ğŸ› ï¸ Hands-on

### Ejercicio 1: Spark SQL
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("SQL Example").getOrCreate()

# Crear vista temporal
df.createOrReplaceTempView("people")

# Consulta SQL
result = spark.sql("""
    SELECT name, AVG(age) as avg_age
    FROM people
    GROUP BY name
    HAVING avg_age > 25
""")
```

### Ejercicio 2: API Estructurada
```python
# Lectura de datos
df = spark.read.format("csv") \
    .option("header", "true") \
    .load("hdfs:///input/data.csv")

# ManipulaciÃ³n
df_transformed = df \
    .select("name", "age") \
    .filter("age > 25") \
    .groupBy("name") \
    .agg({"age": "avg"})
```

### Ejercicio 3: MLlib
```python
from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.feature import VectorAssembler

# Preparar datos
assembler = VectorAssembler(
    inputCols=["feature1", "feature2"],
    outputCol="features"
)

# Crear modelo
rf = RandomForestClassifier(
    labelCol="label",
    featuresCol="features"
)

# Pipeline
pipeline = Pipeline(stages=[assembler, rf])
model = pipeline.fit(training_data)
```

## ğŸ“Š Entregables
- Notebook de anÃ¡lisis SQL
- Pipeline de ML implementado
- Reporte de optimizaciÃ³n

## ğŸ” Recursos Adicionales
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- [MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)
- [Spark Performance Tuning](https://spark.apache.org/docs/latest/tuning.html)

## ğŸ¯ PrÃ³xima SesiÃ³n
- Spark Structured Streaming
- Procesamiento en Tiempo Real
- Windowing y Agregaciones
- IntegraciÃ³n con Fuentes de Datos 