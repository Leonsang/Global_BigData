# ğŸš€ BIG DATA LEARNING PROJECT - SESIONES 0-6
## Ambiente Realista para Aprendizaje de TecnologÃ­as Big Data

### ğŸ¯ **OBJETIVO**
Proporcionar una experiencia **100% prÃ¡ctica y realista** con tecnologÃ­as Big Data, simulando problemas y herramientas de producciÃ³n para formar ingenieros de datos competentes.

### ğŸ† **VALOR DIFERENCIAL**
- âœ… **Cluster distribuido real** (no simulaciones)
- âœ… **Datos realistas** de transporte pÃºblico  
- âœ… **Problemas de producciÃ³n** (fallos, optimizaciÃ³n, troubleshooting)
- âœ… **Herramientas profesionales** (Docker, HDFS, Spark, Kafka)
- âœ… **MetodologÃ­a hands-on** (70% prÃ¡ctica, 30% teorÃ­a)

---

## ğŸ“‹ **REQUISITOS MÃNIMOS**

### Hardware
- **RAM**: 16GB (mÃ­nimo 12GB)
- **CPU**: 4 cores fÃ­sicos
- **Almacenamiento**: 50GB libres SSD
- **Red**: ConexiÃ³n estable a internet

### Software
- **Docker Desktop** 20.10+
- **Docker Compose** 2.0+
- **Git** (para clonar repositorio)
- **VS Code** (recomendado)

---

## ğŸš€ **SETUP RÃPIDO (5 minutos)**

### 1. **Clonar y Configurar**
```bash
git clone <repository-url>
cd Global_BigData

# Para Windows (PowerShell)
.\00-setup\scripts\setup_bigdata_env.ps1 setup

# Para Linux/Mac (Bash)
chmod +x 00-setup/scripts/setup_bigdata_env.sh
./00-setup/scripts/setup_bigdata_env.sh setup
```

### 2. **Validar InstalaciÃ³n**
```bash
# Ejecutar validador automÃ¡tico
python 00-setup/scripts/validate_environment.py

# O verificar manualmente
docker-compose -f 03-environments/development/docker-compose.yml ps
```

### 3. **Acceder a Servicios**
- **Jupyter Lab**: http://localhost:8888
- **HDFS NameNode**: http://localhost:9870
- **Spark Master**: http://localhost:8080
- **Kafka Manager**: http://localhost:9000
- **Portainer**: http://localhost:9443

---

## ğŸ“š **ESTRUCTURA DEL PROYECTO**

```
Global_BigData/
â”œâ”€â”€ ğŸ“ 00-setup/                    # Scripts de configuraciÃ³n
â”‚   â”œâ”€â”€ scripts/                    # Setup automÃ¡tico
â”‚   â””â”€â”€ validation/                 # Tests de validaciÃ³n
â”œâ”€â”€ ğŸ“ 01-sessions/                 # Material por sesiÃ³n
â”‚   â”œâ”€â”€ [session-0-intro](01-sessions/session-0-intro/README.md)            # SesiÃ³n 0: IntroducciÃ³n + Setup
â”‚   â”œâ”€â”€ [session-1-hdfs](01-sessions/session-1-hdfs/README.md)             # SesiÃ³n 1: HDFS Distribuido
â”‚   â”œâ”€â”€ [session-2-mapreduce](01-sessions/session-2-mapreduce/README.md)        # SesiÃ³n 2: MapReduce
â”‚   â”œâ”€â”€ [session-3-spark-rdd](01-sessions/session-3-spark-rdd/README.md)        # SesiÃ³n 3: Spark RDDs y DataFrames
â”‚   â”œâ”€â”€ [session-4-spark-sql](01-sessions/session-4-spark-sql/README.md)        # SesiÃ³n 4: Spark SQL y MLlib
â”‚   â”œâ”€â”€ [session-5-streaming](01-sessions/session-5-streaming/README.md)        # SesiÃ³n 5: Spark Structured Streaming
â”‚   â””â”€â”€ [session-6-kafka](01-sessions/session-6-kafka/README.md)            # SesiÃ³n 6: Apache Kafka
â”œâ”€â”€ ğŸ“ 02-datasets/                 # Datos del proyecto
â”‚   â”œâ”€â”€ raw/                        # Datos originales
â”‚   â”œâ”€â”€ generators/                 # Generadores de datos
â”‚   â””â”€â”€ schemas/                    # Estructura de datos
â”œâ”€â”€ ğŸ“ 03-environments/             # Configuraciones ambiente
â”‚   â””â”€â”€ development/                # Docker Compose + configs
â”œâ”€â”€ ğŸ“ 04-cheatsheets/              # Referencias rÃ¡pidas
â”œâ”€â”€ ğŸ“ 05-monitoring/               # Herramientas monitoreo
â”œâ”€â”€ ğŸ“ 06-solutions/                # Soluciones ejercicios
â””â”€â”€ ğŸ“ 07-presentations/            # Presentaciones del curso
```

---

## ğŸ“ **ROADMAP DE SESIONES**

### **ğŸ“– SESIÃ“N 0: INTRODUCCIÃ“N Y SETUP** *(1.5 horas)*
**Objetivo**: Contexto y ambiente funcionando
- âœ… IntroducciÃ³n a Big Data
- âœ… Sociedad interconectada
- âœ… Setup automÃ¡tico
- âœ… Primer "win" tÃ©cnico

### **ğŸ—‚ï¸ SESIÃ“N 1: HDFS - EL EJÃ‰RCITO DE COMPUTADORAS** *(1.5 horas)*
**Objetivo**: Dominar almacenamiento distribuido
- âš¡ Cluster HDFS multi-nodo
- ğŸ“Š AnÃ¡lisis de distribuciÃ³n
- ğŸ”¥ SimulaciÃ³n de fallos
- ğŸ“ˆ OptimizaciÃ³n

### **âš¡ SESIÃ“N 2: MAPREDUCE - DIVIDE Y VENCERÃS** *(3 horas)*
**Objetivo**: Procesamiento distribuido
- ğŸ§® Jobs MapReduce
- ğŸš€ OptimizaciÃ³n
- ğŸ†š Comparativa con Spark
- ğŸ”§ Troubleshooting

### **ğŸ”¥ SESIÃ“N 3: SPARK RDDs Y DATAFRAMES** *(2 horas)*
**Objetivo**: Procesamiento con Spark
- ğŸ“Š RDDs y transformaciones
- ğŸ¯ DataFrames
- âš¡ OptimizaciÃ³n
- ğŸ”„ Persistencia

### **ğŸ“Š SESIÃ“N 4: SPARK SQL Y MLlib** *(2 horas)*
**Objetivo**: AnÃ¡lisis y ML
- ğŸ¯ Spark SQL
- ğŸ¤– MLlib
- ğŸ“ˆ OptimizaciÃ³n
- ğŸ“Š VisualizaciÃ³n

### **âš¡ SESIÃ“N 5: SPARK STRUCTURED STREAMING** *(2 horas)*
**Objetivo**: Procesamiento en tiempo real
- ğŸŒŠ Structured Streaming
- â° Windowing
- ğŸ“Š Agregaciones
- ğŸ”„ IntegraciÃ³n Kafka

### **ğŸš€ SESIÃ“N 6: APACHE KAFKA** *(2 horas)*
**Objetivo**: Event streaming
- ğŸ“¨ Productores
- ğŸ“¥ Consumidores
- ğŸ”„ Event sourcing
- ğŸ“ˆ Performance

"aqui yatendremos un proyecto git completo que nos servira de ejemplo para aplicar los conocimientos adquiridos en las sesiones anteriores con ejemplos reales y tareas y proyectos que nos permitiran demostrar la aplicacion de los conocimientos adquiridos en las sesiones anteriores"

---

## ğŸ› ï¸ **STACK TECNOLÃ“GICO**

### **Almacenamiento**
- **Hadoop HDFS 3.2.1**: Distributed file system
- **Docker Volumes**: Persistencia de datos

### **Procesamiento**
- **Apache Spark 3.4.0**: Distributed computing
- **Hadoop MapReduce 3.2.1**: Batch processing
- **Apache Kafka 3.4.0**: Event streaming

### **OrquestaciÃ³n**
- **Docker 20.10+**: ContainerizaciÃ³n
- **Docker Compose**: Multi-container

### **Desarrollo**
- **Jupyter Lab**: IDE interactivo
- **Python 3.9**: Lenguaje principal
- **Pandas/NumPy**: Data manipulation

### **Monitoreo**
- **Portainer**: Container management
- **Hadoop Web UIs**: HDFS monitoring
- **Spark Web UI**: Job monitoring
- **Kafka Manager**: Topic management

---

## ğŸ“Š **DATOS DEL PROYECTO**

### **Dataset: Transporte PÃºblico de Lima**
- **Volumen**: 30 dÃ­as de datos histÃ³ricos
- **Registros**: ~100,000 viajes
- **Rutas**: 50 rutas diferentes
- **Distritos**: 15 distritos de Lima
- **Formato**: JSON particionado por fecha/distrito

### **Esquema de Datos**
```json
{
  "trip_id": "T20240115081234",
  "route_id": "R001",
  "date": "2024-01-15",
  "scheduled_time": "08:30:00",
  "delay_minutes": 2.5,
  "passengers_on_board": 45,
  "occupancy_rate": 0.75,
  "district_origin": "Lima Centro",
  "district_destination": "Miraflores",
  "driver_id": "D1234",
  "weather_condition": "Sunny"
}
```

---

## ğŸ”§ **COMANDOS ÃšTILES**

### **GestiÃ³n del Ambiente**
```bash
# Iniciar todos los servicios
docker-compose -f 03-environments/development/docker-compose.yml up -d

# Ver estado de servicios
docker-compose ps

# Ver logs en tiempo real
docker-compose logs -f namenode

# Parar todo
docker-compose down

# Reset completo
./00-setup/scripts/setup_bigdata_env.sh reset
```

### **Comandos HDFS**
```bash
# Listar directorios
hdfs dfs -ls /

# Subir archivos
hdfs dfs -put archivo.csv /destino/

# Ver contenido
hdfs dfs -cat /archivo.txt

# Estado del cluster
hdfs dfsadmin -report
```

### **Comandos Spark**
```bash
# Ejecutar job Spark
spark-submit script.py

# Shell interactivo
pyspark

# Conectar a cluster
pyspark --master spark://spark-master:7077
```

### **Comandos Kafka**
```bash
# Listar topics
kafka-topics.sh --list --bootstrap-server localhost:9092

# Crear topic
kafka-topics.sh --create --topic test --bootstrap-server localhost:9092

# Consumir mensajes
kafka-console-consumer.sh --topic test --bootstrap-server localhost:9092
```

---

## ğŸ†˜ **TROUBLESHOOTING**

### **Problemas Comunes**

#### **ğŸ³ Docker Issues**
```bash
# Docker no inicia
sudo systemctl start docker

# Falta memoria
docker system prune -f

# Containers no responden
docker-compose restart
```

#### **ğŸ—‚ï¸ HDFS Issues**
```bash
# NameNode no inicia
docker logs hdfs_namenode

# DataNode desconectado
docker restart hdfs_datanode1

# Permisos negados
hdfs dfs -chmod 755 /directorio
```

#### **âš¡ Spark Issues**
```bash
# Workers no conectan
docker logs spark_worker_1

# Out of memory
# Ajustar: spark.executor.memory en docker-compose.yml

# Jobs muy lentos
# Verificar: http://localhost:8080 para diagnÃ³stico
```

#### **ğŸš€ Kafka Issues**
```bash
# Broker no inicia
docker logs kafka_broker_1

# Problemas de conexiÃ³n
# Verificar: kafka-topics.sh --describe --topic test

# Consumidores bloqueados
# Resetear offsets: kafka-consumer-groups.sh --reset-offsets
```

---

## ğŸ“ˆ **MÃ‰TRICAS DE Ã‰XITO**

### **TÃ©cnicas**
- âœ… Cluster HDFS con replicaciÃ³n factor 2
- âœ… Spark cluster con 2+ workers
- âœ… Kafka cluster con 3+ brokers
- âœ… Jobs ejecutÃ¡ndose <5 min
- âœ… 0 bloques corruptos

### **Aprendizaje**
- âœ… Configurar cluster Big Data
- âœ… Troubleshoot problemas
- âœ… Optimizar performance
- âœ… Monitorear sistemas
- âœ… Tomar decisiones arquitectÃ³nicas

---

## ğŸ¯ **PRÃ“XIMOS PASOS**

### **Al Completar Sesiones 0-6**
1. **Portfolio Update**: Agregar proyecto Big Data
2. **LinkedIn Skills**: Hadoop, Spark, Kafka
3. **Certificaciones**: Considerar Cloudera/Databricks
4. **Proyectos Avanzados**: ML, Cloud Migration

### **Extensiones Futuras**
- ğŸŒŠ **Kafka Streams** (SesiÃ³n 7)
- ğŸ¤– **Machine Learning** (SesiÃ³n 8)
- â˜ï¸ **Cloud Migration** (SesiÃ³n 9)
- ğŸ”’ **Security & Governance** (SesiÃ³n 10)

---

## ğŸ‘¥ **CONTRIBUCIÃ“N**

### **Para Instructores**
- Cada sesiÃ³n es modular e independiente
- Material diseÃ±ado para 70% prÃ¡ctica / 30% teorÃ­a
- Ejercicios escalables segÃºn nivel del grupo
- Soluciones completas incluidas

### **Para Estudiantes**
- Sigue el orden de sesiones
- Completa todos los checkpoints
- Documenta tus soluciones
- Experimenta mÃ¡s allÃ¡ de los ejercicios

---

## ğŸ“ **SOPORTE**

### **DocumentaciÃ³n**
- ğŸ“– README de cada sesiÃ³n
- ğŸ“ Cheatsheets en `/04-cheatsheets/`
- ğŸ”§ Troubleshooting guides
- ğŸ’¡ Solutions en `/06-solutions/`

### **ValidaciÃ³n AutomÃ¡tica**
```bash
# Ejecutar validador completo
python 00-setup/scripts/validate_environment.py

# Verificar servicios especÃ­ficos
./00-setup/scripts/setup_bigdata_env.sh status
```

---

**ğŸš€ Â¡Listos para dominar Big Data como los ingenieros de Google, Netflix y Amazon!**

# ğŸŒ Big Data Transport Analysis

## Estructura del Proyecto

```
Global_BigData/
â”œâ”€â”€ 00-setup/           # ConfiguraciÃ³n inicial y scripts
â”œâ”€â”€ 01-sessions/        # Sesiones de trabajo
â”œâ”€â”€ 02-datasets/        # Datos y generadores
â”œâ”€â”€ 03-environments/    # Entornos de prÃ¡ctica
â”œâ”€â”€ 04-cheatsheets/     # Referencias rÃ¡pidas
â”œâ”€â”€ 05-monitoring/      # Herramientas de monitoreo
â”œâ”€â”€ 06-solutions/       # Soluciones a ejercicios
â””â”€â”€ 07-presentations/   # Presentaciones
```

## Entornos de PrÃ¡ctica

El proyecto incluye diferentes entornos configurados para cada prÃ¡ctica:

### Entorno de Desarrollo
- UbicaciÃ³n: `03-environments/development/`
- Servicios: HDFS, Spark, Jupyter, Kafka
- Uso: Desarrollo y pruebas generales

### PrÃ¡ctica 1: IntroducciÃ³n a HDFS
- UbicaciÃ³n: `03-environments/practice-01/`
- Servicios: HDFS, Jupyter
- Enfoque: Almacenamiento distribuido

### PrÃ¡ctica 2: Procesamiento con Spark
- UbicaciÃ³n: `03-environments/practice-02/`
- Servicios: HDFS, Spark, Jupyter
- Enfoque: Procesamiento distribuido

### PrÃ¡ctica 3: AnÃ¡lisis en Tiempo Real
- UbicaciÃ³n: `03-environments/practice-03/`
- Servicios: HDFS, Spark, Kafka, Jupyter
- Enfoque: Procesamiento de streaming

## GestiÃ³n de Entornos

Para gestionar los entornos, usa el script `manage_environments.py`:

```bash
# Listar entornos disponibles
python manage_environments.py list

# Iniciar un entorno
python manage_environments.py start practice-01

# Verificar estado
python manage_environments.py status practice-01

# Cambiar de entorno
python manage_environments.py switch practice-02

# Detener entorno
python manage_environments.py stop practice-01
```

## ConfiguraciÃ³n Inicial

1. **Instalar Prerequisitos**:
   ```bash
   # Windows
   cd 00-setup/scripts/windows
   .\install_prerequisites.bat

   # Mac
   cd 00-setup/scripts/mac
   ./install_prerequisites.sh
   ```

2. **Inicializar Entornos**:
   ```bash
   cd 00-setup/scripts/common
   python init_environment.py
   ```

## Servicios Disponibles

- **Jupyter Notebook**: http://localhost:8888
- **Spark UI**: http://localhost:8080
- **HDFS UI**: http://localhost:9870
- **Kafka**: localhost:9092

## Requisitos del Sistema

- **Windows**:
  - Windows 10 Pro/Enterprise/Education (64-bit)
  - 8GB RAM mÃ­nimo (16GB recomendado)
  - 20GB espacio libre en disco
  - Procesador de 64 bits con soporte para virtualizaciÃ³n

- **Mac**:
  - macOS 10.15 o superior
  - 8GB RAM mÃ­nimo (16GB recomendado)
  - 20GB espacio libre en disco
  - Procesador Intel o Apple Silicon

- **Linux**:
  - Ubuntu 20.04 LTS o superior
  - 8GB RAM mÃ­nimo (16GB recomendado)
  - 20GB espacio libre en disco
  - Docker y Docker Compose instalados

## Notas Importantes

1. AsegÃºrate de tener Docker Desktop corriendo antes de ejecutar los scripts
2. Los scripts deben ejecutarse con privilegios de administrador (excepto en Mac)
3. Se recomienda reiniciar el sistema despuÃ©s de la instalaciÃ³n
4. MantÃ©n actualizado el archivo `requirements.txt` con las Ãºltimas versiones de las dependencias
5. En Mac, asegÃºrate de que Homebrew estÃ© instalado y actualizado
6. En Linux, asegÃºrate de tener los permisos necesarios para ejecutar Docker sin sudo

## SoluciÃ³n de Problemas

Si encuentras algÃºn problema durante la instalaciÃ³n o configuraciÃ³n, consulta:
- `00-setup/docs/troubleshooting.md` para problemas generales
- El README especÃ­fico de cada entorno en `03-environments/[entorno]/README.md`

## ContribuciÃ³n

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request