# âš¡ SESIÃ“N 2: MAPREDUCE - DIVIDE Y VENCERÃS
## Procesamiento Distribuido Real con Hadoop MapReduce

### ğŸ¯ **OBJETIVOS DE APRENDIZAJE**
Al finalizar esta sesiÃ³n, serÃ¡s capaz de:
- âœ… Implementar jobs MapReduce reales para procesar datos masivos
- âœ… Optimizar performance de procesamiento distribuido
- âœ… Resolver problemas de data skew y cuellos de botella
- âœ… Comparar MapReduce vs Spark en casos reales
- âœ… Monitorear y debuggear jobs distribuidos

### ğŸ§  **CONCEPTOS CORE QUE DOMINARÃS**
- **Map Phase**: Divide el problema en sub-problemas
- **Shuffle & Sort**: Redistribuye datos eficientemente  
- **Reduce Phase**: Combina resultados parciales
- **Combiners**: OptimizaciÃ³n de red y performance
- **Partitioners**: Control de distribuciÃ³n de datos

---

## ğŸ¬ **HOOK INICIAL: El Problema de Netflix**

> *"En 2006, Netflix procesaba 1TB de logs diarios. Un servidor tardaba 18 horas. Con 100 servidores... Â¿18 minutos? Â¡NO! Tardaba 6 horas. Â¿Por quÃ©?"*

**El Problema**:
- Network I/O era el cuello de botella
- Datos se transferÃ­an mÃºltiples veces
- No habÃ­a optimizaciÃ³n de localidad

**La SoluciÃ³n MapReduce**:
- "Mover cÃ³digo a los datos, no datos al cÃ³digo"
- Procesamiento local en cada nodo
- MÃ­nima transferencia de red
- **Resultado**: 18 horas â†’ 45 minutos

**Â¡Hoy vas a experimentar esta transformaciÃ³n!**

---

## ğŸ—ï¸ **ARQUITECTURA MAPREDUCE QUE IMPLEMENTAREMOS**

```
ğŸ“Š DATOS DE ENTRADA (HDFS)
         â†“
ğŸ—‚ï¸ INPUT SPLITS (128MB cada uno)
         â†“
âš¡ MAP PHASE (Paralelo en cada nodo)
  â”œâ”€ Mapper 1 (DataNode 1)
  â”œâ”€ Mapper 2 (DataNode 1) 
  â”œâ”€ Mapper 3 (DataNode 2)
  â””â”€ Mapper 4 (DataNode 2)
         â†“
ğŸ”„ SHUFFLE & SORT (Red mÃ­nima)
         â†“
âš¡ REDUCE PHASE (Paralelo)
  â”œâ”€ Reducer 1 â†’ Resultados parciales
  â””â”€ Reducer 2 â†’ Resultados parciales
         â†“
ğŸ“Š SALIDA FINAL (HDFS)
```

---

## âš¡ **EJERCICIOS PRÃCTICOS REALISTAS**

### **Ejercicio 1: AnÃ¡lisis de Rutas de Transporte (45 min)**
**Problema Real**: Identificar rutas con mayor demanda y retrasos

**Tu Job MapReduce**:
1. **Map**: Extraer (ruta, pasajeros, retraso) de cada viaje
2. **Reduce**: Sumar pasajeros totales y retraso promedio por ruta
3. **Output**: Top 10 rutas por demanda y problemas

**CÃ³digo Base**:
```python
def map_rutas(line):
    # Procesar lÃ­nea JSON de viaje
    trip = json.loads(line)
    route_id = trip['route_id']
    passengers = trip['passengers_on_board']
    delay = trip['delay_minutes']
    
    emit(route_id, (passengers, delay, 1))

def reduce_rutas(route_id, values):
    total_passengers = sum(v[0] for v in values)
    total_delay = sum(v[1] for v in values)
    total_trips = sum(v[2] for v in values)
    avg_delay = total_delay / total_trips
    
    emit(route_id, (total_passengers, avg_delay, total_trips))
```

### **Ejercicio 2: AnÃ¡lisis de Patrones Temporales (60 min)**
**Problema Real**: Optimizar frecuencias de buses por hora del dÃ­a

**Tu Job MapReduce**:
1. **Map**: Extraer (hora, distrito, demanda) de cada viaje
2. **Combiner**: Pre-agregar datos localmente (Â¡OptimizaciÃ³n!)
3. **Reduce**: Calcular demanda total por hora y distrito
4. **Analysis**: Identificar patrones de horas pico

### **Ejercicio 3: DetecciÃ³n de Data Skew (45 min)**
**Problema Real**: Algunos distritos generan 10x mÃ¡s datos

**Tu MisiÃ³n**:
1. Identificar distribuciÃ³n desigual de datos
2. Implementar partitioner customizado
3. Comparar performance antes/despuÃ©s
4. Documentar mejoras obtenidas

---

## ğŸ”§ **HERRAMIENTAS DE MONITOREO**

### **Job Tracker Web UI**
- http://localhost:8088 - Resource Manager
- http://localhost:19888 - Job History Server
- http://localhost:8042 - Node Manager

### **MÃ©tricas Clave a Monitorear**
```bash
# Estado de jobs
yarn application -list -appStates RUNNING

# Performance de mappers/reducers  
yarn logs -applicationId application_xxx

# UtilizaciÃ³n de recursos
yarn node -list -all

# AnÃ¡lisis de cuellos de botella
hadoop job -history all
```

---

## ğŸ“Š **OPTIMIZACIONES QUE IMPLEMENTAREMOS**

### **1. Combiners (Local Reduce)**
```python
# Sin Combiner: 1M records â†’ Network â†’ Reduce
# Con Combiner: 1M records â†’ 100 records â†’ Network â†’ Reduce
# ReducciÃ³n de trÃ¡fico: 99%
```

### **2. Custom Partitioner**  
```python
class DistrictPartitioner:
    def getPartition(key, value, numPartitions):
        # Distribuir uniformemente por distrito
        return hash(key.district) % numPartitions
```

### **3. ConfiguraciÃ³n Optimizada**
```xml
<property>
  <name>mapreduce.map.memory.mb</name>
  <value>1024</value>
</property>
<property>
  <name>mapreduce.reduce.memory.mb</name>
  <value>2048</value>
</property>
```

---

## ğŸ†š **MAPREDUCE vs SPARK: COMPARATIVA REAL**

### **Mismo Job, Diferentes Engines**

| MÃ©trica | MapReduce | Spark |
|---------|-----------|-------|
| Tiempo de EjecuciÃ³n | 8 min | 3 min |
| Uso de Memoria | 2GB | 6GB |
| Fault Tolerance | Disk-based | Memory-based |
| Learning Curve | Steeper | Gentler |
| Use Case Ideal | Batch ETL | Interactive Analytics |

### **Â¿CuÃ¡ndo Usar QuÃ©?**
- **MapReduce**: ETL masivo, datos muy grandes, presupuesto limitado
- **Spark**: Analytics iterativo, ML, desarrollo rÃ¡pido

---

## ğŸ¯ **ENTREGABLES DE LA SESIÃ“N**

### **1. Transport Analytics Report**
- Top 10 rutas por demanda
- AnÃ¡lisis de patrones temporales
- IdentificaciÃ³n de cuellos de botella
- Recomendaciones operativas

### **2. Performance Optimization Case Study**
- AnÃ¡lisis before/after de optimizaciones
- Impacto de combiners y partitioners
- Recommendations para jobs futuros
- DocumentaciÃ³n de best practices

### **3. MapReduce vs Spark Comparison**
- Benchmark del mismo job en ambos engines
- Trade-offs de performance vs recursos
- Decision framework para futuros proyectos

---

## ğŸš€ **VALOR PROFESIONAL**

**Habilidades que desarrollarÃ¡s**:
- Pensamiento distribuido (clave para arquitectura)
- OptimizaciÃ³n de performance (diferencia senior/junior)
- Troubleshooting de jobs distribuidos (skill escaso)
- ComparaciÃ³n de tecnologÃ­as (architectural decision making)

**Estas competencias te posicionan para**:
- **Data Engineer Sr**: $85k-125k
- **Big Data Architect**: $100k-150k  
- **Performance Engineer**: $95k-135k
- **Technical Lead**: $110k-160k

---

## ğŸ“‹ **CHECKLIST DE FINALIZACIÃ“N**

- [ ] Job MapReduce ejecutÃ¡ndose en cluster distribuido
- [ ] AnÃ¡lisis de rutas completado con insights
- [ ] Optimizaciones implementadas y documentadas
- [ ] Comparativa MapReduce vs Spark realizada
- [ ] Performance tuning documentado
- [ ] Troubleshooting de al menos 1 problema real

**ğŸ‰ Â¡Listo para dominar Spark en SesiÃ³n 3!**